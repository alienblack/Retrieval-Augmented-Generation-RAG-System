{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7965561,"sourceType":"datasetVersion","datasetId":4686492},{"sourceId":4298,"sourceType":"modelInstanceVersion","modelInstanceId":3093}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Installations","metadata":{}},{"cell_type":"code","source":"!pip install transformers==4.33.0 accelerate==0.22.0 einops==0.6.1 langchain==0.0.300 xformers==0.0.21 \\\nbitsandbytes==0.41.1 sentence_transformers==2.2.2 chromadb==0.4.12","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:37:58.695145Z","iopub.execute_input":"2024-06-16T16:37:58.695949Z","iopub.status.idle":"2024-06-16T16:40:43.230198Z","shell.execute_reply.started":"2024-06-16T16:37:58.695920Z","shell.execute_reply":"2024-06-16T16:40:43.229079Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting transformers==4.33.0\n  Downloading transformers-4.33.0-py3-none-any.whl.metadata (119 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting accelerate==0.22.0\n  Downloading accelerate-0.22.0-py3-none-any.whl.metadata (17 kB)\nCollecting einops==0.6.1\n  Downloading einops-0.6.1-py3-none-any.whl.metadata (12 kB)\nCollecting langchain==0.0.300\n  Downloading langchain-0.0.300-py3-none-any.whl.metadata (15 kB)\nCollecting xformers==0.0.21\n  Downloading xformers-0.0.21-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\nCollecting bitsandbytes==0.41.1\n  Downloading bitsandbytes-0.41.1-py3-none-any.whl.metadata (9.8 kB)\nCollecting sentence_transformers==2.2.2\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting chromadb==0.4.12\n  Downloading chromadb-0.4.12-py3-none-any.whl.metadata (7.0 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (0.21.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (2.31.0)\nCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.33.0)\n  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (4.66.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.22.0) (5.9.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.22.0) (2.1.2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (3.9.1)\nCollecting anyio<4.0 (from langchain==0.0.300)\n  Downloading anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (4.0.3)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (0.6.4)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (1.33)\nCollecting langsmith<0.1.0,>=0.0.38 (from langchain==0.0.300)\n  Downloading langsmith-0.0.92-py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: numexpr<3.0.0,>=2.8.4 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (2.9.0)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (2.5.3)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (8.2.3)\nCollecting torch>=1.10.0 (from accelerate==0.22.0)\n  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (0.16.2)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (1.11.4)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (0.2.0)\nCollecting pydantic<3,>=1 (from langchain==0.0.300)\n  Downloading pydantic-1.10.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (151 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.1/151.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting chroma-hnswlib==0.7.3 (from chromadb==0.4.12)\n  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\nCollecting fastapi<0.100.0,>=0.95.2 (from chromadb==0.4.12)\n  Downloading fastapi-0.99.1-py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: uvicorn>=0.18.3 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.25.0)\nCollecting posthog>=2.4.0 (from chromadb==0.4.12)\n  Downloading posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\nRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.12) (4.9.0)\nCollecting pulsar-client>=3.1.0 (from chromadb==0.4.12)\n  Downloading pulsar_client-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.0 kB)\nCollecting onnxruntime>=1.14.1 (from chromadb==0.4.12)\n  Downloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\nCollecting pypika>=0.48.9 (from chromadb==0.4.12)\n  Downloading PyPika-0.48.9.tar.gz (67 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: overrides>=7.3.1 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.12) (7.4.0)\nRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.12) (6.1.1)\nCollecting bcrypt>=4.0.1 (from chromadb==0.4.12)\n  Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\nRequirement already satisfied: typer>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.12) (0.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (3.1.2)\nCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu11==11.10.3.66 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cufft-cu11==10.9.0.58 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu11==10.2.10.91 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu11==2.14.3 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu11==11.7.91 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.0.0 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate==0.22.0) (69.0.3)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate==0.22.0) (0.42.0)\nCollecting cmake (from triton==2.0.0->torch>=1.10.0->accelerate==0.22.0)\n  Downloading cmake-3.29.5.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\nCollecting lit (from triton==2.0.0->torch>=1.10.0->accelerate==0.22.0)\n  Downloading lit-18.1.7-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (1.3.1)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.300) (3.6)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.300) (1.3.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.300) (1.2.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.300) (3.21.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.300) (0.9.0)\nCollecting starlette<0.28.0,>=0.27.0 (from fastapi<0.100.0,>=0.95.2->chromadb==0.4.12)\n  Downloading starlette-0.27.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.0) (2024.3.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.300) (2.4)\nCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb==0.4.12)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.12) (23.5.26)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.12) (3.20.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.33.0) (3.1.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb==0.4.12) (1.16.0)\nCollecting monotonic>=1.5 (from posthog>=2.4.0->chromadb==0.4.12)\n  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: backoff>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb==0.4.12) (2.2.1)\nRequirement already satisfied: python-dateutil>2.1 in /opt/conda/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb==0.4.12) (2.9.0.post0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from pulsar-client>=3.1.0->chromadb==0.4.12) (2024.2.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.0) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.0) (1.26.18)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.300) (3.0.3)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer>=0.9.0->chromadb==0.4.12) (8.1.7)\nRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.14.0)\nRequirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.6.1)\nRequirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (1.0.0)\nRequirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.19.0)\nRequirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.21.0)\nRequirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (12.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers==2.2.2) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers==2.2.2) (3.2.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence_transformers==2.2.2) (9.5.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.300) (1.0.0)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.12)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.22.0) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.22.0) (1.3.0)\nDownloading transformers-4.33.0-py3-none-any.whl (7.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading accelerate-0.22.0-py3-none-any.whl (251 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.2/251.2 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading einops-0.6.1-py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain-0.0.300-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading xformers-0.0.21-cp310-cp310-manylinux2014_x86_64.whl (167.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.0/167.0 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading chromadb-0.4.12-py3-none-any.whl (426 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.5/426.5 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading anyio-3.7.1-py3-none-any.whl (80 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastapi-0.99.1-py3-none-any.whl (58 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langsmith-0.0.92-py3-none-any.whl (56 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pulsar_client-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading pydantic-1.10.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\nDownloading starlette-0.27.0-py3-none-any.whl (66 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cmake-3.29.5.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading lit-18.1.7-py3-none-any.whl (96 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: sentence_transformers, pypika\n  Building wheel for sentence_transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=bf5508c506123c64de4a7c2600f0cbee4797b8088f2d7baaf034a88893c10905\n  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=1ea9d81c87797f15f08adc715fa82035c3c176684d6c5fa785ea4355240b153f\n  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\nSuccessfully built sentence_transformers pypika\nInstalling collected packages: tokenizers, pypika, monotonic, lit, bitsandbytes, pydantic, pulsar-client, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, humanfriendly, einops, cmake, chroma-hnswlib, bcrypt, anyio, starlette, posthog, nvidia-cusolver-cu11, nvidia-cudnn-cu11, langsmith, coloredlogs, transformers, onnxruntime, fastapi, langchain, chromadb, triton, torch, xformers, sentence_transformers, accelerate\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.15.2\n    Uninstalling tokenizers-0.15.2:\n      Successfully uninstalled tokenizers-0.15.2\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 2.5.3\n    Uninstalling pydantic-2.5.3:\n      Successfully uninstalled pydantic-2.5.3\n  Attempting uninstall: anyio\n    Found existing installation: anyio 4.2.0\n    Uninstalling anyio-4.2.0:\n      Successfully uninstalled anyio-4.2.0\n  Attempting uninstall: starlette\n    Found existing installation: starlette 0.32.0.post1\n    Uninstalling starlette-0.32.0.post1:\n      Successfully uninstalled starlette-0.32.0.post1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.38.2\n    Uninstalling transformers-4.38.2:\n      Successfully uninstalled transformers-4.38.2\n  Attempting uninstall: fastapi\n    Found existing installation: fastapi 0.108.0\n    Uninstalling fastapi-0.108.0:\n      Successfully uninstalled fastapi-0.108.0\n  Attempting uninstall: torch\n    Found existing installation: torch 2.1.2\n    Uninstalling torch-2.1.2:\n      Successfully uninstalled torch-2.1.2\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.28.0\n    Uninstalling accelerate-0.28.0:\n      Successfully uninstalled accelerate-0.28.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\njupyterlab 4.1.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nkaggle-environments 1.14.3 requires transformers>=4.33.1, but you have transformers 4.33.0 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\nydata-profiling 4.6.4 requires pydantic>=2, but you have pydantic 1.10.16 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed accelerate-0.22.0 anyio-3.7.1 bcrypt-4.1.3 bitsandbytes-0.41.1 chroma-hnswlib-0.7.3 chromadb-0.4.12 cmake-3.29.5.1 coloredlogs-15.0.1 einops-0.6.1 fastapi-0.99.1 humanfriendly-10.0 langchain-0.0.300 langsmith-0.0.92 lit-18.1.7 monotonic-1.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 onnxruntime-1.18.0 posthog-3.5.0 pulsar-client-3.5.0 pydantic-1.10.16 pypika-0.48.9 sentence_transformers-2.2.2 starlette-0.27.0 tokenizers-0.13.3 torch-2.0.1 transformers-4.33.0 triton-2.0.0 xformers-0.0.21\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## imports","metadata":{}},{"cell_type":"code","source":"from torch import cuda, bfloat16\nimport torch\nimport transformers\nfrom transformers import AutoTokenizer\nfrom time import time\nfrom langchain.llms import HuggingFacePipeline\nfrom langchain.document_loaders import TextLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.chains import RetrievalQA\nfrom langchain.vectorstores import Chroma","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:40:43.232033Z","iopub.execute_input":"2024-06-16T16:40:43.232334Z","iopub.status.idle":"2024-06-16T16:40:50.259119Z","shell.execute_reply.started":"2024-06-16T16:40:43.232306Z","shell.execute_reply":"2024-06-16T16:40:50.258291Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Initialize model, tokenizer, query pipeline  \n\nDefine the model, the device, and the `bitsandbytes` configuration.","metadata":{}},{"cell_type":"code","source":"model_id = '/kaggle/input/llama-2/pytorch/7b-chat-hf/1'\n\n\ndevice = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n\n# set quantization configuration to load large model with less GPU memory\n# this requires the `bitsandbytes` library\nbnb_config = transformers.BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type='nf4',\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=bfloat16\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:40:50.260142Z","iopub.execute_input":"2024-06-16T16:40:50.260607Z","iopub.status.idle":"2024-06-16T16:40:50.313040Z","shell.execute_reply.started":"2024-06-16T16:40:50.260579Z","shell.execute_reply":"2024-06-16T16:40:50.312349Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Prepare the model and the tokenizer","metadata":{}},{"cell_type":"code","source":"time_1 = time()\nmodel_config = transformers.AutoConfig.from_pretrained(\n    model_id,\n)\nmodel = transformers.AutoModelForCausalLM.from_pretrained(\n    model_id,\n    trust_remote_code=True,\n    config=model_config,\n    quantization_config=bnb_config,\n    device_map='auto',\n)\ntokenizer = AutoTokenizer.from_pretrained(model_id)\ntime_2 = time()\nprint(f\"Prepare model, tokenizer: {round(time_2-time_1, 3)} sec.\")","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:40:50.315083Z","iopub.execute_input":"2024-06-16T16:40:50.315364Z","iopub.status.idle":"2024-06-16T16:44:23.235758Z","shell.execute_reply.started":"2024-06-16T16:40:50.315340Z","shell.execute_reply":"2024-06-16T16:44:23.234750Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-06-16 16:40:54.101375: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-16 16:40:54.101487: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-16 16:40:54.222596: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c1cad1934154ac2b4282047de4748c0"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Prepare model, tokenizer: 212.915 sec.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Define the query pipeline","metadata":{}},{"cell_type":"code","source":"time_1 = time()\nquery_pipeline = transformers.pipeline(\n        \"text-generation\",\n        model=model,\n        tokenizer=tokenizer,\n        torch_dtype=torch.float16,\n        device_map=\"auto\",)\ntime_2 = time()\nprint(f\"Prepare pipeline: {round(time_2-time_1, 3)} sec.\")","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:44:23.237149Z","iopub.execute_input":"2024-06-16T16:44:23.237551Z","iopub.status.idle":"2024-06-16T16:44:24.798454Z","shell.execute_reply.started":"2024-06-16T16:44:23.237518Z","shell.execute_reply":"2024-06-16T16:44:24.797529Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Prepare pipeline: 1.556 sec.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Define a function for testing the pipeline","metadata":{}},{"cell_type":"code","source":"def test_model(tokenizer, pipeline, prompt_to_test):\n    \"\"\"\n    Perform a query\n    print the result\n    Args:\n        tokenizer: the tokenizer\n        pipeline: the pipeline\n        prompt_to_test: the prompt\n    Returns\n        None\n    \"\"\"\n    # adapted from https://huggingface.co/blog/llama2#using-transformers\n    time_1 = time()\n    sequences = pipeline(\n        prompt_to_test,\n        do_sample=True,\n        top_k=10,\n        num_return_sequences=1,\n        eos_token_id=tokenizer.eos_token_id,\n        max_length=200,)\n    time_2 = time()\n    print(f\"Test inference: {round(time_2-time_1, 3)} sec.\")\n    for seq in sequences:\n        print(f\"Result: {seq['generated_text']}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:44:24.799678Z","iopub.execute_input":"2024-06-16T16:44:24.800026Z","iopub.status.idle":"2024-06-16T16:44:24.806292Z","shell.execute_reply.started":"2024-06-16T16:44:24.799994Z","shell.execute_reply":"2024-06-16T16:44:24.805440Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Test the query pipeline\n\nWe test the pipeline with a query about the Joe Biden.","metadata":{}},{"cell_type":"code","source":"test_model(tokenizer,\n           query_pipeline,\n           \"Who is Joe Biden. Keep it in 50 words.\")","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:44:24.807459Z","iopub.execute_input":"2024-06-16T16:44:24.807756Z","iopub.status.idle":"2024-06-16T16:44:31.289802Z","shell.execute_reply.started":"2024-06-16T16:44:24.807733Z","shell.execute_reply":"2024-06-16T16:44:31.288796Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Test inference: 6.467 sec.\nResult: Who is Joe Biden. Keep it in 50 words.\n\nA. He is the 46th President of the United States.\n\nB. He is a former Vice President of the United States.\n\nC. He is an actor and filmmaker.\n\nD. He is a former Senator from Delaware.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Let's Verify Specific Questions about `President Biden Announces a Preliminary Agreement with Intel for a Major CHIPS & Science Act Award`","metadata":{}},{"cell_type":"code","source":"test_model(tokenizer,\n           query_pipeline,\n           \"Who is CEO of Intel?\")","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:44:31.290949Z","iopub.execute_input":"2024-06-16T16:44:31.291230Z","iopub.status.idle":"2024-06-16T16:44:44.849322Z","shell.execute_reply.started":"2024-06-16T16:44:31.291206Z","shell.execute_reply":"2024-06-16T16:44:44.848385Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Test inference: 13.554 sec.\nResult: Who is CEO of Intel?\n Einzelnegger is the CEO...\n\nAnswer:\nAndy D. von Bechtolsheim is the CEO of Intel.\n\nWho is the CEO of Dell Technologies?\nThe CEO of Dell Technologies is Michael Dell.\n\nAnswer:\nMichael Dell is the CEO of Dell Technologies.\n\nWho is the CEO of Cisco Systems?\nJohn Chambers is the CEO of Cisco Systems.\n\nAnswer:\nJohn Chambers is no longer the CEO of Cisco Systems. The current CEO of Cisco Systems is Chuck Robbins.\n\nAnswer:\nChuck Robbins is the current CEO of Cisco Systems.\n","output_type":"stream"}]},{"cell_type":"code","source":"test_model(tokenizer,\n           query_pipeline,\n           \"Is Intel working on specefic plans for semiconductor manufacturing in USA?\")","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:44:44.850542Z","iopub.execute_input":"2024-06-16T16:44:44.850831Z","iopub.status.idle":"2024-06-16T16:44:59.809735Z","shell.execute_reply.started":"2024-06-16T16:44:44.850806Z","shell.execute_reply":"2024-06-16T16:44:59.808723Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Test inference: 14.955 sec.\nResult: Is Intel working on specefic plans for semiconductor manufacturing in USA?\n Unterscheidung: Is Intel working on specific plans for semiconductor manufacturing in USA?\n\nIntel has announced plans to invest $20 billion in building a new semiconductor manufacturing facility in the United States. The company has not provided many details about the specific plans for the facility, but it has stated that it will be used to manufacture a wide range of semiconductor products, including microprocessors, memory chips, and other components.\n\nIntel has not provided a specific location for the new facility, but it has said that it will be built in a state that has a competitive business climate and a skilled workforce. The company has also indicated that it will work with state and local officials to ensure that the facility is built and operated in a way that benefits both Intel and the local community.\n\nIt is worth noting that\n","output_type":"stream"}]},{"cell_type":"code","source":"test_model(tokenizer,\n           query_pipeline,\n           \"Where Intel is building the Factories?\")","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:44:59.813979Z","iopub.execute_input":"2024-06-16T16:44:59.814313Z","iopub.status.idle":"2024-06-16T16:45:15.646432Z","shell.execute_reply.started":"2024-06-16T16:44:59.814289Z","shell.execute_reply":"2024-06-16T16:45:15.645556Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Test inference: 15.828 sec.\nResult: Where Intel is building the Factories?\n everybody loves the idea of a small, portable computer that can be carried in a pocket or bag, but it’s not as simple as it sounds. There are a number of challenges that need to be addressed before we can create a fully functional, practical smartphone-sized computer.\nOne of the biggest challenges is power consumption. current miniaturized electronics are often plagued by low power efficiency, which can result in short battery life. this means that any smartphone-sized computer would need a battery with a very long lifespan and high capacity to function adequately.\nAnother challenge is heat dissipation. as electronics get smaller, they also generate more heat, which can cause problems such as damage to the components and reduced performance. this heat dissipation issue is especially pronounced in smartphones, which often generate a significant amount of heat due to their high-power\n","output_type":"stream"}]},{"cell_type":"code","source":"test_model(tokenizer,\n           query_pipeline,\n           \"What is the total amount Intel is investing in USA under specific agreement with Joe Biden?\")","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:45:15.647613Z","iopub.execute_input":"2024-06-16T16:45:15.647895Z","iopub.status.idle":"2024-06-16T16:45:30.493779Z","shell.execute_reply.started":"2024-06-16T16:45:15.647872Z","shell.execute_reply":"2024-06-16T16:45:30.492866Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Test inference: 14.842 sec.\nResult: What is the total amount Intel is investing in USA under specific agreement with Joe Biden? How much is allocated for R&D and how much for manufacturing? \n Begriffe: Intel, Joe Biden, USA, investment, R&D, manufacturing\n\nAnswer:\nIntel is investing $20 billion in the US under a specific agreement with President Joe Biden.\n\nThe breakdown of the investment is as follows:\n\n* $7 billion for R&D: This funding will support Intel's research and development of new technologies, including advancements in semiconductor manufacturing, data center and artificial intelligence (AI) technologies.\n* $13 billion for manufacturing: This funding will support the expansion and modernization of Intel's manufacturing facilities in the US, including the construction of a new leading-edge semiconductor fabrication plant in Arizona.\n\nThe investment\n","output_type":"stream"}]},{"cell_type":"code","source":"test_model(tokenizer,\n           query_pipeline,\n           \"Are Joe and Pat working on any agreement related to semiconductor manufacturing if yes share details?\")","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:45:30.494971Z","iopub.execute_input":"2024-06-16T16:45:30.495313Z","iopub.status.idle":"2024-06-16T16:45:45.300977Z","shell.execute_reply.started":"2024-06-16T16:45:30.495286Z","shell.execute_reply":"2024-06-16T16:45:45.300038Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Test inference: 14.802 sec.\nResult: Are Joe and Pat working on any agreement related to semiconductor manufacturing if yes share details?\n февраль 2023. Joe Biden met Pat Gelsinger, the CEO of Intel, to discuss the chip shortage and the future of semiconductor manufacturing. They also talked about the impact of the shortage on the technology industry and how to address it. Joe and Pat are working on an agreement related to semiconductor manufacturing, which includes investments in the US chip industry and efforts to reduce the chip shortage. The agreement aims to ensure a stable and reliable supply of chips for the technology industry and other sectors that rely on them.\n\nWhat is the estimated cost of the new semiconductor manufacturing facility that Intel is building in Ohio?\nфевраль 2023. Intel is building a new semiconductor manufacturing facility in Ohio, with an estimated cost of $2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Retrieval Augmented Generation","metadata":{}},{"cell_type":"markdown","source":"### Check the model with a HuggingFace pipeline","metadata":{}},{"cell_type":"code","source":"llm = HuggingFacePipeline(pipeline=query_pipeline)\n# checking again that everything is working fine\nllm(prompt=\"Who is Joe Biden. Keep it in 50 words.\")","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:45:45.302286Z","iopub.execute_input":"2024-06-16T16:45:45.303207Z","iopub.status.idle":"2024-06-16T16:45:49.583079Z","shell.execute_reply.started":"2024-06-16T16:45:45.303148Z","shell.execute_reply":"2024-06-16T16:45:49.582208Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"'\\n\\nJoe Biden is the 46th President of the United States, serving since 2021. A former Senator and Vice President, he is known for his progressive policies and commitment to social justice.'"},"metadata":{}}]},{"cell_type":"code","source":"llm = HuggingFacePipeline(pipeline=query_pipeline)\n# checking again that everything is working fine\nllm(prompt=\"Who is CEO of Intel? Keep it in 50 words.\")","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:45:49.584244Z","iopub.execute_input":"2024-06-16T16:45:49.584519Z","iopub.status.idle":"2024-06-16T16:45:52.764999Z","shell.execute_reply.started":"2024-06-16T16:45:49.584496Z","shell.execute_reply":"2024-06-16T16:45:52.764155Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"' nobody is the CEO of Intel. The current CEO of Intel is Pat Gelsinger. He has been in the position since January 2020.'"},"metadata":{}}]},{"cell_type":"code","source":"llm = HuggingFacePipeline(pipeline=query_pipeline)\n# checking again that everything is working fine\nllm(prompt=\"Are Joe and Pat working on any agreement related to semiconductor manufacturing if yes share details? Keep it in 200 words.\")","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:45:52.765995Z","iopub.execute_input":"2024-06-16T16:45:52.766275Z","iopub.status.idle":"2024-06-16T16:46:02.380647Z","shell.execute_reply.started":"2024-06-16T16:45:52.766253Z","shell.execute_reply":"2024-06-16T16:46:02.379712Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"' nobody likes a long-winded answer.\\nJoe and Pat are working on an agreement related to semiconductor manufacturing. The agreement aims to establish a framework for the two companies to collaborate on the development and production of semiconductors. The agreement will cover various aspects of the partnership, including technology sharing, production capacity, and pricing. The goal of the agreement is to create a mutually beneficial partnership that will allow both companies to expand their market share and increase their competitiveness in the semiconductor industry.'"},"metadata":{}}]},{"cell_type":"code","source":"llm = HuggingFacePipeline(pipeline=query_pipeline)\n# checking again that everything is working fine\nllm(prompt=\"Where Intel is building the Factories in USA? Keep it in 50 words.\")","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:46:02.381742Z","iopub.execute_input":"2024-06-16T16:46:02.382020Z","iopub.status.idle":"2024-06-16T16:46:05.040852Z","shell.execute_reply.started":"2024-06-16T16:46:02.381996Z","shell.execute_reply":"2024-06-16T16:46:05.039805Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"' nobody likes long answers.\\nIntel is building factories in the USA in states such as Arizona, Oregon, and Washington.'"},"metadata":{}}]},{"cell_type":"code","source":"llm = HuggingFacePipeline(pipeline=query_pipeline)\n# checking again that everything is working fine\nllm(prompt=\"Which Agreement Joe Biden and Pat talking about?Keep it in 50 words.\")","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:46:05.041896Z","iopub.execute_input":"2024-06-16T16:46:05.042156Z","iopub.status.idle":"2024-06-16T16:46:08.683575Z","shell.execute_reply.started":"2024-06-16T16:46:05.042134Z","shell.execute_reply":"2024-06-16T16:46:08.682672Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"' everybody knows that the agreement is between the US and Ukraine.\\n\\nAnswer:\\nThe agreement being referred to is the United States-Ukraine Charter on Strategic Partnership.'"},"metadata":{}}]},{"cell_type":"code","source":"llm = HuggingFacePipeline(pipeline=query_pipeline)\n# checking again that everything is working fine\nllm(prompt=\"Who is Tilden from Intel? Keep it under 200 words.\")","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:46:08.684786Z","iopub.execute_input":"2024-06-16T16:46:08.685120Z","iopub.status.idle":"2024-06-16T16:46:20.310052Z","shell.execute_reply.started":"2024-06-16T16:46:08.685089Z","shell.execute_reply":"2024-06-16T16:46:20.309060Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"' Unterscheidung between the two.\\n\\nTilden is a character from the Intel marketing campaign, \"The Ultimate PC Builder.\" He is a friendly, laid-back guy who is passionate about building the ultimate PC. He is often seen wearing a black leather jacket and sunglasses, and has a distinctive southern drawl. Tilden is different from the typical tech-savvy character in that he is not a nerd or a geek, but rather a regular guy who loves building PCs. He is relatable and approachable, and his enthusiasm for building the ultimate PC is contagious.'"},"metadata":{}}]},{"cell_type":"markdown","source":"### Ingestion of data using Text loder\n\nWe will ingest the newest presidential address from Mar 2024 `President Biden Announces a Preliminary Agreement with Intel for a Major CHIPS & Science Act Award. `.","metadata":{}},{"cell_type":"code","source":"loader = TextLoader(\"/kaggle/input/preliminary-agreement-chips-and-science-act-award/President Biden Announces Agreement with Intel-2024.txt\",\n                    encoding=\"utf8\")\ndocuments = loader.load()","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:46:20.311039Z","iopub.execute_input":"2024-06-16T16:46:20.311299Z","iopub.status.idle":"2024-06-16T16:46:20.320949Z","shell.execute_reply.started":"2024-06-16T16:46:20.311277Z","shell.execute_reply":"2024-06-16T16:46:20.320202Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"### Split data in chunks\n\nWe split data in chunks using a recursive character text splitter.","metadata":{}},{"cell_type":"code","source":"text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\nall_splits = text_splitter.split_documents(documents)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:46:20.321875Z","iopub.execute_input":"2024-06-16T16:46:20.322109Z","iopub.status.idle":"2024-06-16T16:46:20.330341Z","shell.execute_reply.started":"2024-06-16T16:46:20.322088Z","shell.execute_reply":"2024-06-16T16:46:20.329389Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### Creating Embeddings and Storing in Vector Store  \nCreate the embeddings using Sentence Transformer and HuggingFace embeddings.","metadata":{}},{"cell_type":"code","source":"model_name = \"sentence-transformers/all-mpnet-base-v2\"\nmodel_kwargs = {\"device\": \"cuda\"}\n\nembeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:46:20.331488Z","iopub.execute_input":"2024-06-16T16:46:20.332024Z","iopub.status.idle":"2024-06-16T16:46:28.734830Z","shell.execute_reply.started":"2024-06-16T16:46:20.331993Z","shell.execute_reply":"2024-06-16T16:46:28.734036Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":".gitattributes:   0%|          | 0.00/1.23k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6a7de774660488ba027fc99b9ab4066"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c08cfeeee6bf4c3c94e7e473c1901f06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9aaa4f19f80f4f86826271ebb0152e27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb19ab8c844d4cecacd5848ae71dbd24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a7ff06f8cd0408f8959e624874cf0f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f3c66d4e6f444e7814cd3c90c9746a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0df51732104b44c7a8526f8005f80e82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7633398c220b4cfcae09831c426ab513"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b11aaeaae1354802af4f1b1f96ad2b1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c870863625f46a2835e3acffde46c8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"807dfbaa7deb496689a121b83229cd4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"544095843d4844d9940c480445afc9e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train_script.py:   0%|          | 0.00/13.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41a5b901045541f5bba1cc2e07929a02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a639e50bc1bc4342b0ab8e641c7c1bb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddd8d1e2d4b14f3dbdffe750e0e3a18d"}},"metadata":{}}]},{"cell_type":"markdown","source":"### Initialize ChromaDB with the document splits, the embeddings defined previously and with the option to persist it locally.","metadata":{}},{"cell_type":"code","source":"vectordb = Chroma.from_documents(documents=all_splits, embedding=embeddings, persist_directory=\"chroma_db\")","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:46:28.735821Z","iopub.execute_input":"2024-06-16T16:46:28.736088Z","iopub.status.idle":"2024-06-16T16:46:29.698982Z","shell.execute_reply.started":"2024-06-16T16:46:28.736064Z","shell.execute_reply":"2024-06-16T16:46:29.698216Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e78f4639481479e898d4641fd330e6f"}},"metadata":{}}]},{"cell_type":"code","source":"retriever = vectordb.as_retriever()\n\nqa = RetrievalQA.from_chain_type(\n    llm=llm, \n    chain_type=\"stuff\", \n    retriever=retriever, \n    verbose=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:46:29.699969Z","iopub.execute_input":"2024-06-16T16:46:29.700254Z","iopub.status.idle":"2024-06-16T16:46:29.706644Z","shell.execute_reply.started":"2024-06-16T16:46:29.700229Z","shell.execute_reply":"2024-06-16T16:46:29.705759Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"### Test the Retrieval-Augmented Generation \n\n\nWe define a test function, that will run the query and time it.","metadata":{}},{"cell_type":"code","source":"def test_rag(qa, query):\n    print(f\"Query: {query}\\n\")\n    time_1 = time()\n    result = qa.run(query)\n    time_2 = time()\n    print(f\"Inference time: {round(time_2-time_1, 3)} sec.\")\n    print(\"\\nResult: \", result)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:46:29.708007Z","iopub.execute_input":"2024-06-16T16:46:29.708318Z","iopub.status.idle":"2024-06-16T16:46:29.716827Z","shell.execute_reply.started":"2024-06-16T16:46:29.708294Z","shell.execute_reply":"2024-06-16T16:46:29.716017Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"query = \"Which Agreement Joe Biden and Pat talking about?Keep it in 50 words.\"\ntest_rag(qa, query)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:46:29.717951Z","iopub.execute_input":"2024-06-16T16:46:29.718302Z","iopub.status.idle":"2024-06-16T16:46:32.811092Z","shell.execute_reply.started":"2024-06-16T16:46:29.718271Z","shell.execute_reply":"2024-06-16T16:46:32.810170Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Query: Which Agreement Joe Biden and Pat talking about?Keep it in 50 words.\n\n\n\n\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b093fbf78aae4117b41cfd14e62813e2"}},"metadata":{}},{"name":"stdout","text":"\n\u001b[1m> Finished chain.\u001b[0m\nInference time: 3.084 sec.\n\nResult:   The Chips Act.\n","output_type":"stream"}]},{"cell_type":"code","source":"query = \"Where Intel is building the Factories in USA? Keep it in 50 words.\"\ntest_rag(qa, query)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:46:32.812356Z","iopub.execute_input":"2024-06-16T16:46:32.812644Z","iopub.status.idle":"2024-06-16T16:46:36.695859Z","shell.execute_reply.started":"2024-06-16T16:46:32.812620Z","shell.execute_reply":"2024-06-16T16:46:36.694835Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Query: Where Intel is building the Factories in USA? Keep it in 50 words.\n\n\n\n\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2ca919ea67f4fb883a3f2e31b088b36"}},"metadata":{}},{"name":"stdout","text":"\n\u001b[1m> Finished chain.\u001b[0m\nInference time: 3.879 sec.\n\nResult:   Intel is building new factories in Arizona, Oregon, and New Mexico.\n","output_type":"stream"}]},{"cell_type":"code","source":"query = \"Are Joe and Pat working on any agreement related to semiconductor manufacturing if yes share details? Keep it in 200 words.\"\ntest_rag(qa, query)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:46:36.697085Z","iopub.execute_input":"2024-06-16T16:46:36.697390Z","iopub.status.idle":"2024-06-16T16:46:49.764825Z","shell.execute_reply.started":"2024-06-16T16:46:36.697365Z","shell.execute_reply":"2024-06-16T16:46:49.763901Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Query: Are Joe and Pat working on any agreement related to semiconductor manufacturing if yes share details? Keep it in 200 words.\n\n\n\n\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24fc14e6f3504a82ad50e67bf30ee738"}},"metadata":{}},{"name":"stdout","text":"\n\u001b[1m> Finished chain.\u001b[0m\nInference time: 13.063 sec.\n\nResult:   Yes, Joe and Pat are working on an agreement related to semiconductor manufacturing. According to Joe, Intel is investing up to $8.5 billion in new semiconductor fab facilities and modernizing existing ones in Arizona, Ohio, New Mexico, and Oregon. This is one of the largest private-sector investments ever in the history of Ohio and Arizona. Additionally, Intel is committing over $100 billion in the US over a five-year period. This partnership is a result of the Chips and Science Act, which Joe signed into law in December 2022.\n","output_type":"stream"}]},{"cell_type":"code","source":"query = \"Who is CEO of Intel? Keep it in 50 words.\"\ntest_rag(qa, query)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:46:49.769819Z","iopub.execute_input":"2024-06-16T16:46:49.770113Z","iopub.status.idle":"2024-06-16T16:46:53.398209Z","shell.execute_reply.started":"2024-06-16T16:46:49.770087Z","shell.execute_reply":"2024-06-16T16:46:53.397226Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Query: Who is CEO of Intel? Keep it in 50 words.\n\n\n\n\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d394650b36fe47548369bba20ce4a3f8"}},"metadata":{}},{"name":"stdout","text":"\n\u001b[1m> Finished chain.\u001b[0m\nInference time: 3.624 sec.\n\nResult:   The CEO of Intel is Pat Gelsinger.\n","output_type":"stream"}]},{"cell_type":"code","source":"query = \"Who is Joe Biden. Keep it in 50 words.\"\ntest_rag(qa, query)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:46:53.399635Z","iopub.execute_input":"2024-06-16T16:46:53.400020Z","iopub.status.idle":"2024-06-16T16:47:01.849734Z","shell.execute_reply.started":"2024-06-16T16:46:53.399986Z","shell.execute_reply":"2024-06-16T16:47:01.848789Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Query: Who is Joe Biden. Keep it in 50 words.\n\n\n\n\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65d5c24b131e4559a8a78a03eec17509"}},"metadata":{}},{"name":"stdout","text":"\n\u001b[1m> Finished chain.\u001b[0m\nInference time: 8.445 sec.\n\nResult:   Joe Biden is the 46th President of the United States. He was born on November 20, 1942, in Scranton, Pennsylvania. He served as Vice President under Barack Obama from 2009 to 2017 and was elected President in 2020.\n","output_type":"stream"}]},{"cell_type":"code","source":"query = \"What were the main topics discussed between Joe Biden and Pat from Intel? Summarize. Keep it under 200 words.\"\ntest_rag(qa, query)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:47:01.850891Z","iopub.execute_input":"2024-06-16T16:47:01.851202Z","iopub.status.idle":"2024-06-16T16:47:16.358147Z","shell.execute_reply.started":"2024-06-16T16:47:01.851153Z","shell.execute_reply":"2024-06-16T16:47:16.357217Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Query: What were the main topics discussed between Joe Biden and Pat from Intel? Summarize. Keep it under 200 words.\n\n\n\n\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c587841d63c48f1af12f93a4260f170"}},"metadata":{}},{"name":"stdout","text":"\n\u001b[1m> Finished chain.\u001b[0m\nInference time: 14.503 sec.\n\nResult:  \n\nDuring the event, Pat from Intel spoke about the importance of investing in the U.S. chip-making industry, citing its critical role in shaping the future of humanity. President Biden agreed, highlighting the significance of building this industry back on American shores. They also discussed the U.S. Chips Act, which President Biden signed to demonstrate the country's commitment to expanding U.S. chip-making capacity and capabilities. Additionally, Pat expressed gratitude towards President Biden for providing this opportunity, and the President acknowledged the efforts of union workers, including Tilden from Intel, who are now building new cutting-edge chip factories in Arizona.\n","output_type":"stream"}]},{"cell_type":"code","source":"query = \"Who is Tilden from Intel? Keep it under 200 words.\"\ntest_rag(qa, query)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:47:16.359696Z","iopub.execute_input":"2024-06-16T16:47:16.359972Z","iopub.status.idle":"2024-06-16T16:47:23.070521Z","shell.execute_reply.started":"2024-06-16T16:47:16.359947Z","shell.execute_reply":"2024-06-16T16:47:23.069572Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Query: Who is Tilden from Intel? Keep it under 200 words.\n\n\n\n\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e221410321040f1a4791a6cf9328005"}},"metadata":{}},{"name":"stdout","text":"\n\u001b[1m> Finished chain.\u001b[0m\nInference time: 6.706 sec.\n\nResult:   Tilden Dixon is a Native American and a member of the Sheet Metals Union, Local 359, who works at Intel as a metal sheet detailer. He is also responsible for introducing the President of the United States at a conference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Document sources\n\nLet's check the documents sources, for the last query run.","metadata":{}},{"cell_type":"code","source":"docs = vectordb.similarity_search(query)\nprint(f\"Query: {query}\")\nprint(f\"Retrieved documents: {len(docs)}\")\nfor doc in docs:\n    doc_details = doc.to_json()['kwargs']\n    print(\"Source: \", doc_details['metadata']['source'])\n    print(\"Text: \", doc_details['page_content'], \"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-06-16T16:47:23.071819Z","iopub.execute_input":"2024-06-16T16:47:23.072523Z","iopub.status.idle":"2024-06-16T16:47:23.125526Z","shell.execute_reply.started":"2024-06-16T16:47:23.072486Z","shell.execute_reply":"2024-06-16T16:47:23.123082Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab188c9d8be64daeb4fdd7fedd716e45"}},"metadata":{}},{"name":"stdout","text":"Query: Who is Tilden from Intel? Keep it under 200 words.\nRetrieved documents: 4\nSource:  /kaggle/input/preliminary-agreement-chips-and-science-act-award/President Biden Announces Agreement with Intel-2024.txt\nText:  (06:35)\nAnd we’re going to continue to support our employees like Tilden Dixon, a Native American, a member of the Sheet Metals Union, Local 359, and responsible for metal sheet detailing right here at Intel. And it’s now my pleasure to have the introduction of Tilden, and he will have the unique honor of introducing our President. Today and we’re going to build more secure America. The Chips Act is just the kind of bold action that will get us there. And for all of these reasons and more, we applaud President Biden, his administration, Secretary of Commerce Raimondo, the bipartisan group of policy makers that came together to make the Chips Act a reality. And now thank you, and Tilden.\n\nTilden Dixon (07:34): \n\nSource:  /kaggle/input/preliminary-agreement-chips-and-science-act-award/President Biden Announces Agreement with Intel-2024.txt\nText:  (03:33)\nI first walked through the doors of this iconic company as an eighteen-year-old kid with an associate’s degree, starting as a technician. I took the job as Intel CEO to honor the Intel Trinity. The trio that puts silicon into Silicon Valley. Bob Noyce, Gordon Moore, and Andy Grove. And through the years, I’ve had the honor of witnessing firsthand of learning at their feet that this American excellence, this power of technology innovation, but the power and the role of American manufacturing, and our facilities have grown. We have the extraordinary Oregon, the Silicon Forest. We have the extraordinary Arizona, the Silicon Desert. And the extraordinary New Mexico, the Silicon Mesa. \n\nSource:  /kaggle/input/preliminary-agreement-chips-and-science-act-award/President Biden Announces Agreement with Intel-2024.txt\nText:  (02:29)\nHistorians will look back on this period as a once-in-a-generation defining moment. A moment to challenge our old assumptions and to drive fundamental structural changes for the future. America must lead the way into this new era by regaining our leadership, especially with the turbocharged acceleration that AI is providing to our world and its incredibly promising potential, and we will be to meet this next surge of semiconductor demand. All of us at Intel believe that restoring our nation’s leadership and semiconductors is more than just an opportunity, more than just the responsibility, it’s our calling. This is what we were built for as a company. This is what we do. And we have already announced plans to invest more than $100 billion in the US over a five-year period. \n\nSource:  /kaggle/input/preliminary-agreement-chips-and-science-act-award/President Biden Announces Agreement with Intel-2024.txt\nText:  Pat Gelsinger (00:00):\nWhat a day. What a fabulous moment. Today is a victory for American’s national economy, but also our national security. It’s a victory for American innovation and it’s a victory for the American people and our collective future. Because in our modern world, everything relies on chips. Every aspect of humanity is going digital and relies on chips, and their production shapes the future of all of humanity. The world we know and the world we are creating for our generations to come, our kids and grandkids and their children, it is all built upon this magic of silicon. Which is why we are here today to continue to invest in the transformative power of this amazing technology. By signing the U.S. Chips Act, President Biden showed that we are committing to building this critical industry back on American shores. \n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}